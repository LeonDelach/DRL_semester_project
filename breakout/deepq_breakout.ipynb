{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "536027fb",
   "metadata": {},
   "source": [
    "# Deep Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0fdc1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380b32ef",
   "metadata": {},
   "source": [
    "## Environment and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0520a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"ALE/Breakout-v5\")  # render_mode=\"human\"\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") #cuda:1  ?\n",
    "\n",
    "FIRE=1    # because it is breakout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf7c59",
   "metadata": {},
   "source": [
    "## Replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88343258",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3639b4f",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d96d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(2, 18, kernel_size = 3, stride = 1, padding = 1)\n",
    "        # self.pool = torch.nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.fc1 = torch.nn.Linear(18 * dim_x * dim_y, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, n_actions-1)    # for breakout we do not need to select the FIRE action\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # x = self.pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)  # start_dim=1 because we want to process batches as well as single elements\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8169ad6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b720df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lives': 5, 'episode_frame_number': 0, 'frame_number': 0}\n",
      "(210, 160, 3)\n",
      "(170, 150)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "\n",
    "print(info)\n",
    "def preprocess(state):\n",
    "    gray_state = np.apply_along_axis(lambda x: int(np.sum(x) > 0), 2, state)\n",
    "    crop_state = gray_state[25:-15,5:-5]\n",
    "    return crop_state\n",
    "\n",
    "print(state.shape) \n",
    "prp = preprocess(state)\n",
    "print(prp.shape)\n",
    "plt.imshow(prp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8e3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(observe):\n",
    "    processed_observe = np.uint8(\n",
    "        resize(rgb2gray(observe), (84, 84), mode='constant') * 255)\n",
    "    return processed_observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1169189b",
   "metadata": {},
   "source": [
    "## Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f5f67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4   # to decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04facbbb",
   "metadata": {},
   "source": [
    "## Variables initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea28b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = env.action_space.n\n",
    "state, info = env.reset()\n",
    "prp = preprocess(state)\n",
    "obs_x = prp.shape[0]\n",
    "obs_y = prp.shape[1]\n",
    "\n",
    "policy_net = DQN(obs_x, obs_y, n_actions).to(device)\n",
    "target_net = DQN(obs_x, obs_y, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f38e6",
   "metadata": {},
   "source": [
    "## Select action with epsilon-greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157f8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "def update_epsilon():\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    return eps_threshold\n",
    "\n",
    "def select_action(state, eps_threshold):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    steps_done += 1\n",
    "    # epsilon-greedy\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return torch.argmax(policy_net(state)).view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0eac4a",
   "metadata": {},
   "source": [
    "## One step optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d0f6d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    print(policy_net(state_batch).shape)\n",
    "    print(action_batch.shape)\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    # using target_net to improve stability because V(s') = max Q(s', a') that is used in the update rule\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    loss = nn.SmoothL1Loss()(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe0931ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee41af9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa1b4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_update():\n",
    "    # Soft update of the target network's weights\n",
    "    # θ′ ← τ θ + (1 −τ )θ′\n",
    "    target_net_state_dict = target_net.state_dict()\n",
    "    policy_net_state_dict = policy_net.state_dict()\n",
    "    for key in policy_net_state_dict:\n",
    "        target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "    target_net.load_state_dict(target_net_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467a8ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n",
      "torch.Size([128, 3])\n",
      "torch.Size([128, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m memory\u001b[38;5;241m.\u001b[39mpush(in_dqn, action, next_state, reward)\n\u001b[0;32m     27\u001b[0m in_dqn \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m---> 28\u001b[0m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m soft_update()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n",
      "Cell \u001b[1;32mIn[10], line 27\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSmoothL1Loss()(state_action_values, expected_state_action_values\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_value_(policy_net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\semester\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\semester\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "for i_episode in range(num_episodes):\n",
    "    state, info = env.reset()\n",
    "    obs, rwd, termin, trunc, info = env.step(FIRE)\n",
    "    frame = np.array([preprocess(state), preprocess(obs)])\n",
    "    in_dqn = torch.tensor(frame, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    rewards_all = []\n",
    "    for t in count():\n",
    "        action = select_action(in_dqn, update_epsilon())\n",
    "        while action >= 3:\n",
    "            action -= 1\n",
    "        if action >= FIRE:\n",
    "            action += 1\n",
    "        obs, rwd, termin, trunc, new_info = env.step(action.item())\n",
    "        rewards_all.append(rwd)\n",
    "        reward = torch.tensor([rwd], device=device)\n",
    "        done = termin or trunc\n",
    "        if termin:\n",
    "            next_state = None\n",
    "        else:\n",
    "            frame[0] = frame[1]\n",
    "            frame[1] = preprocess(obs)\n",
    "            next_state = torch.tensor(frame, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        if action >= FIRE:\n",
    "            action -= 1\n",
    "        memory.push(in_dqn, action, next_state, reward)\n",
    "        in_dqn = next_state\n",
    "        optimize_model()\n",
    "        soft_update()\n",
    "        if done:\n",
    "            break \n",
    "        if new_info['lives'] != info['lives']:\n",
    "            obs, rwd, termin, trunc, info = env.step(FIRE)\n",
    "        else:\n",
    "            info = new_info\n",
    "    rewards.append(sum(rewards_all))\n",
    "plt.plot(rewards)\n",
    "plt.savefig(\"rewards.png\") \n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f93c90",
   "metadata": {},
   "source": [
    "## Test one game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eeb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.wrappers.RecordVideo(gym.make(\"ALE/Breakout-v5\", render_mode='rgb_array'), \"videos\")\n",
    "state, info = env.reset()\n",
    "env.start_video_recorder()\n",
    "obs, rwd, termin, trunc, info = env.step(FIRE)\n",
    "frame = np.array([preprocess(state), preprocess(obs)])\n",
    "     \n",
    "for t in count():\n",
    "    in_dqn = torch.tensor(frame, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    action = select_action(in_dqn, 0) # we play greedy\n",
    "    print(action)\n",
    "    while action >= 3:\n",
    "        action -= 1\n",
    "    if action >= FIRE:\n",
    "        action += 1\n",
    "\n",
    "    obs, rwd, termin, trunc, new_info = env.step(action.item())\n",
    "    done = termin or trunc\n",
    "    \n",
    "    if termin:\n",
    "        next_state = None\n",
    "    else:\n",
    "        frame[0] = frame[1]\n",
    "        frame[1] = preprocess(obs)\n",
    "        next_state = torch.tensor(frame, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    if action >= FIRE:\n",
    "        action -= 1\n",
    "    in_dqn = next_state\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    if new_info['lives'] != info['lives']:\n",
    "        obs, rwd, termin, trunc, info = env.step(FIRE)\n",
    "    else:\n",
    "        info = new_info\n",
    "    # print(\"Hello\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69500fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make('ALE/Breakout-v5', render_mode='rgb_array')\n",
    "video_folder = '/videos'\n",
    "episode_trigger = lambda episode_id: episode_id == 0  # start recording at episode 0\n",
    "env = gym.wrappers.RecordVideo(env, video_folder, episode_trigger=episode_trigger)\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()  # replace with your own action selection logic\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    \n",
    "env.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769de14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(env.metadata['render_fps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(env.video_recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee36a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab28bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
